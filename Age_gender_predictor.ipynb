{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d34e7-5fa4-4610-a834-2cebf62b1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.mat'):  # Filter for .mat files\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39089cde-9786-4dbb-a64b-9d99c609c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_count = 0\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.jpg'):  # Check for image files\n",
    "            image_count += 1\n",
    "\n",
    "print(f\"Number of images found: {image_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a9d89-ebaa-451a-b295-ff979ed3d25d",
   "metadata": {},
   "source": [
    "# Checking structure of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d36860-8cdf-4e94-9eab-0fbd3505fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "mat_file_path = '/kaggle/input/imdb-wiki-faces-dataset/imdb_crop/imdb.mat'  # Update with the correct path\n",
    "mat_data = scipy.io.loadmat(mat_file_path)\n",
    "\n",
    "# Print the keys in the .mat file\n",
    "print(\"Keys in the .mat file:\")\n",
    "for key in mat_data.keys():\n",
    "    if not key.startswith('__'):  # Skip internal keys like '__header__', '__version__', etc.\n",
    "        print(key)\n",
    "\n",
    "# Inspect the structure of the 'imdb' field (if it exists)\n",
    "if 'imdb' in mat_data:\n",
    "    print(\"\\nStructure of 'imdb':\")\n",
    "    print(mat_data['imdb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56eedfc-1cd3-48f0-8443-9d08cbbac6ee",
   "metadata": {},
   "source": [
    "# Loading dataset, converting it to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520f5d2-1b84-47ba-a258-bacbc9baf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the .mat file\n",
    "mat_file_path = '/kaggle/input/imdb-wiki-faces-dataset/imdb_crop/imdb.mat'  # Update with the correct path\n",
    "mat_data = scipy.io.loadmat(mat_file_path)\n",
    "\n",
    "# Extract the 'imdb' structured array\n",
    "imdb_data = mat_data['imdb'][0][0]\n",
    "\n",
    "# Extract relevant fields\n",
    "\n",
    "image_paths = imdb_data[2][0]  # Full path to the image\n",
    "genders = imdb_data[3][0]  # Gender (1: male, 0: female)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ddcaa-0006-49c5-ad52-6959fdfe76ff",
   "metadata": {},
   "source": [
    "# Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54373176-d5ad-4783-bcfb-787f00ae8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_image_paths = [item[0] for item in image_paths]\n",
    "df_path=pd.DataFrame(list_image_paths)\n",
    "df_path.rename(columns={0: 'path'}, inplace=True)\n",
    "\n",
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dabff34-f6d3-4ca5-bf3b-1049991a5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender=pd.DataFrame(genders)\n",
    "df_gender.rename(columns={0: 'gender'}, inplace=True)\n",
    "df_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd27c4-a7cd-4419-ae48-e0669026b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract 'dob' from 'image_path'\n",
    "def extract_dob(path):\n",
    "    # Split the filename to extract the date\n",
    "    parts = path.split('_')\n",
    "    dob_str = parts[-2]  # e.g., '1899-5-10'\n",
    "    return dob_str\n",
    "\n",
    "# Apply the function to the 'image_path' column\n",
    "list_dob = df_path['path'].apply(extract_dob).to_frame('dob')\n",
    "df_dob=pd.DataFrame(list_dob)\n",
    "\n",
    "df_dob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537d67a-0d1b-4de0-98e6-8a5ab3daccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract 'photo_taken' from 'image_path'\n",
    "def extract_photo_taken(image_path):\n",
    "    # Split the filename to extract the year\n",
    "    parts = image_path.split('_')\n",
    "    photo_taken = int(parts[-1].split('.')[0])  # e.g., '1968.jpg' -> 1968\n",
    "    return photo_taken\n",
    "\n",
    "# Apply the function to the 'image_path' column in df_path\n",
    "df_photo_taken = df_path['path'].apply(extract_photo_taken).to_frame('photo_taken')\n",
    "df_photo_taken\n",
    "#df=pd.DataFrame(list_photo_taken)\n",
    "#df_photo_taken.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112bd35b-0bb9-4985-915d-dc2f252068a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from 'dob' (assuming 'dob' is in the format 'YYYY-MM-DD')\n",
    "df_dob['dob_year'] = df_dob['dob'].apply(lambda x: int(x.split('-')[0]))\n",
    "\n",
    "# Calculate age\n",
    "df_age = (df_photo_taken['photo_taken'] - df_dob['dob_year']).to_frame(name='age')\n",
    "\n",
    "# Display the first few rows\n",
    "df_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dead827-26a1-4dd0-a9f1-eb4c9d079692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined=pd.concat([df_path,df_gender,df_dob,df_photo_taken,df_age],axis=1)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1af93-5afb-4ba6-aa04-d7f4d7502fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "output_csv_path = '/kaggle/working/imdb_processed_data.csv'\n",
    "df_combined.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Processed CSV file saved to: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09655d-ea0b-4e1d-9591-354996ef1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, df, base_dir, batch_size, target_size):\n",
    "        self.df = df\n",
    "        self.base_dir = base_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_paths = self.df.iloc[batch_indexes]['path']\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for path in batch_paths:\n",
    "            # Prefix the base_dir to the image path\n",
    "            full_path = os.path.join(self.base_dir, path)\n",
    "            image = self.preprocess_image(full_path)\n",
    "            if image is not None:\n",
    "                batch_images.append(image)\n",
    "                batch_labels.append(self.df.iloc[batch_indexes]['age'].values[0])\n",
    "        return np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Failed to read image: {image_path}\")\n",
    "            return None\n",
    "        image = cv2.resize(image, self.target_size)\n",
    "        image = image.astype('float32') / 255.0  # Normalize\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2332bd-4579-4eb4-b662-dd55af89b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where the images are stored\n",
    "base_dir = '/kaggle/input/imdb-wiki-faces-dataset/imdb_crop/'\n",
    "\n",
    "# Create the data generator\n",
    "batch_size = 32  # Adjust based on your memory limits\n",
    "target_size = (224, 224)\n",
    "train_generator = DataGenerator(df_combined, base_dir, batch_size, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333a40c-142a-4cf2-b3b1-c44066486dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras-applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9eea0-8d1f-4427-93cd-d14ddd343292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras==2.12.0 tensorflow==2.12.0 keras-vggface==0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a49b4f-88c8-4272-b671-8b97706ee82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the VGGFace model\n",
    "base_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3))\n",
    "print(\"VGGFace model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c50303-eed8-436e-9825-29c148c48f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "# Load the pre-trained VGGFace model\n",
    "base_model = VGGFace(model='vgg16', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers for age prediction\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='linear')(x)  # Regression for age prediction\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07545d-9bd6-46b9-9744-f89c639a765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the generator\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e49a3a-47f3-4f2b-a478-39362dbd386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Age_Sex_Detection.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
